{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sound_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMgCYzvYbERMCBOy5yB1d4n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmouts/PPS_Telemed/blob/main/heart_sound_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA8u39O-wWfq"
      },
      "source": [
        "# Ανάλυση Ήχου\n",
        "\n",
        "Στο εργαστήριο αυτό θα ασχοληθούμε την Ανάλυση Ήχου, χρησιμοποιώντας μια νέα βιβλιοθήκη Python: **pyAudioAnalysis** [https://github.com/tyiannak/pyAudioAnalysis]. θα χρησιμοποιηθούν δεδομένα από μια Πρόκληση του 2011, ένα Δίκτυο Αριστείας υποστηριζόμενο από την Ευρωπαϊκή Ένωση (http://www.peterjbentley.com/heartchallenge/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDsaGSv-x0A3"
      },
      "source": [
        "!git clone https://github.com/tyiannak/pyAudioAnalysis.git\n",
        "!pip install -q -r pyAudioAnalysis/requirements.txt\n",
        "!pip install -q -e pyAudioAnalysis/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehkRphoezcKt"
      },
      "source": [
        "## Εξαγωγή χαρακτηριστικών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_JwQTrwDwp9"
      },
      "source": [
        "Υπάρχουν δύο στάδια στην μεθοδολογία εξαγωγής ηχητικών χαρακτηριστικών:\n",
        "\n",
        "\n",
        "*   Εξαγωγή χαρακτηριστικών Μικρής Διάρκειας (Short-term): Γίνεται με τη χρήση της συνάρτησης `feature_extraction()` από το αρχείο `ShortTermFeatures.py`. Χωρίζει το εισαγόμενο σήμα σε μικρά χρονικά παράθυρα (frames) και υπολογίζει κάποια χαρακτηριστικά για το κάθε παράθυρο. Αυτή η διαδικασία οδηγεί σε μια σειρά από λίστες χαρακτηριστικών για όλο το σήμα\n",
        "*   Εξαγωγή χαρακτηριστικών Μέσης Διάρκειας (Mid-term): Σε πολλές περιπτώσεις το σήμα αντιπροσωπεύεται από στατιστικές των χαρακτηριστικών μικρής διάρκειας. Η συνάρτηση `mid_feature_extraction()` από το αρχείο `MidTermFeatures.py` εξάγει στατιστικές (πχ μέση τιμή και τυπική απόκλιση) σε κάθε σειρά χαρακτηριστικών μικρής διάρκειας.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgQIg11pzqbi"
      },
      "source": [
        "Το pyAudioAnalysis υποστηρίζει την εξαγωγή 34 χαρακτηριστικών (features) από αρχεία ήχου. Ας δούμε 2 από αυτά: **Zero Crossing Rate - ZCR** (The rate of sign-changes of the signal during the duration of a particular frame) και **Energy** (The sum of squares of the signal values, normalized by the respective frame length)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltPu4m212sa3"
      },
      "source": [
        "!apt-get install -qq ffmpeg\n",
        "!apt-get install -qq python3-magic\n",
        "!pip install -q python-magic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN6K8WDyHrk4"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/pyAudioAnalysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2tFXvM4-kY"
      },
      "source": [
        "from pyAudioAnalysis import audioBasicIO\n",
        "from pyAudioAnalysis import ShortTermFeatures\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwL7_rGfOYKU"
      },
      "source": [
        "\n",
        "Για να διαβαστούν τα ηχητικά δείγματα καλούμε τη συνάρτηση `read_audio_file()` από το αρχείο `audioBasicIO.py`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6LKS9BWOgH4"
      },
      "source": [
        "[Fs, x] = audioBasicIO.read_audio_file(\"pyAudioAnalysis/pyAudioAnalysis/data/doremi.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBD0kabrORhY"
      },
      "source": [
        "# Διάγραμμα με την κυματομορφή\n",
        "import numpy\n",
        "timeX = numpy.arange(0, x.shape[0] / float(Fs), 1.0 / Fs)\n",
        "plt.plot(timeX, x)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oki8WE7j89ad"
      },
      "source": [
        "Ο  επόμενος κώδικας χρησιμοποιεί τη συνάρτηση `feature_extraction()` από το αρχείο `ShortTermFeatures.py` για την εξαγωγή χαρακτηριστικών μικρής διάρκειας ενός ηχητικού σήματος. Θέτουμε χρονικό παράθυρο (frame) 50 msecs και βήμα 25 msecs (με 50% επικάλυψη)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN2NHOZd5mtb"
      },
      "source": [
        "F, f_names = ShortTermFeatures.feature_extraction(x, Fs, 0.050*Fs, 0.025*Fs)\n",
        "plt.subplot(2,1,1); plt.plot(F[0,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[0]) \n",
        "plt.subplot(2,1,2); plt.plot(F[1,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[1]); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69rgT0Lv79IY"
      },
      "source": [
        "O παραπάνω κώδικας επίσης κάνει το διάγραμμα σειράς των δύο πρώτων χαρακτηριστικών: `zero crossing rate` και `signal energy`. Η συνάρτηση `feature_extraction()` επιστρέφει έναν πίνακα numpy  με 34 γραμμές και  N στήλες, όπου N το πλήθος των short-term frames που χωράνε στην εγγραφή του ήχου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3cag-_LHKNP"
      },
      "source": [
        "## Οπτική Ανάλυση του Ήχου"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rup_OWznIVHh"
      },
      "source": [
        "### Φασματικό Διάγραμμα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWoK3Ga8LPQJ"
      },
      "source": [
        "[fs, x] = audioBasicIO.read_audio_file(\"pyAudioAnalysis/pyAudioAnalysis/data/doremi.wav\")\n",
        "x = audioBasicIO.stereo_to_mono(x)\n",
        "specgram, TimeAxis, FreqAxis = ShortTermFeatures.spectrogram(x, fs, round(fs * 0.040),round(fs * 0.040), True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOEJsbLLMq2T"
      },
      "source": [
        "### Χρωματικό Διάγραμμα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqcAJk0yMuLe"
      },
      "source": [
        "specgram, TimeAxis, FreqAxis = ShortTermFeatures.chromagram(x, fs, round(fs * 0.040),\n",
        "                                                 round(fs * 0.040), True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr77Zz6RMjKr"
      },
      "source": [
        "## Εκπαίδευση ενός Ταξινομητή Ήχου\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugspvSM5QCM3"
      },
      "source": [
        "Στην συνέχεια θα εκπαιδεύσουμε έναν ταξινομητή που χρησιμοποιεί Cross-Validation για να διαλέξει την βέλτιστη παράμετρο για τον ταξινομητή (πχ τη παράμετρο soft margin C για SVM, το πλήθος των δέντρων για Random Forests, ο αριθμός των γειτόνων k για Knn κλπ.) Το παραγόμενο μοντέλο σώζεται στη θέση που ορίζουμε με την παράμετρο –o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_D6UXRgYHog"
      },
      "source": [
        "Πρώτα όμως ας φορτώσουμε τα αρχεία εκπαίδευσης, και τα αρχεία για το τελικό τέστ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzjC4k8FQJi_"
      },
      "source": [
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get( 'https://github.com/kmouts/PPS_MultiComms/blob/master/AudioAnaysisData.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjb4GeV6dKT"
      },
      "source": [
        "ls sampleData/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUPJZaOJYVJi"
      },
      "source": [
        "ls trainingData/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_4QqI4dOPD4"
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUlGs507NbcN"
      },
      "source": [
        "!python pyAudioAnalysis/pyAudioAnalysis/audioAnalysis.py trainClassifier -i trainingData/cat/ trainingData/dog/ --method svm -o models/svmSM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpNFWbz50i8s"
      },
      "source": [
        "%ls -la models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKr2OQEUPeVh"
      },
      "source": [
        "### Ταξινόμηση ‘άγνωστων’ ήχων\n",
        "\n",
        "Ας δούμε τώρα πόσο καλά τα πάει ο ταξινομητής μας:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnJl80_Ptxk"
      },
      "source": [
        "!python pyAudioAnalysis/pyAudioAnalysis/audioAnalysis.py classifyFolder -i sampleData/ --model svm --classifier models/svmSM --details\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNgAJX7RHTZ"
      },
      "source": [
        "## Αφαίρεση σιγής"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN8XT4yvoBZi"
      },
      "source": [
        "Η συνάρτηση `silence_removal()` από το αρχείο `audioSegmentation.py` παίρνει σαν είσοδο ένα αρχείο ηχογράφησης και εξάγει τμήματα που αντιστοιχούν σε ηχητικά γεγονότα. Με αυτό το τρόπο, τμήματα \"σιγής\" αφαιρούνται από το σήμα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kHUyXC-RLmj"
      },
      "source": [
        "Αυτό επιτυγχάνεται με μια ημι-εποπτευόμενη (semi-supervised) προσέγγιση: Πρώτα εκπαιδεύεται ένα SVM μοντέλο στο να διακρίνει frames υψηλής/χαμηλής ενέργειας. Για το σκοπό αυτό γίνεται χρήση των 10% των υψηλότερων και 10% των χαμηλότερων ενεργειακά πλαισίων. Το παραγόμενο μοντέλο τρέχει σε όλο το αρχείο (με έξοδο την πιθανότητα) και με δυναμική κατωφλίωση (επιλογή –weight) για  να διακρίνει τα ενεργά τμήματα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF_go4xMpzIu"
      },
      "source": [
        "Η συνάρτηση `silence_removal()` έχει τα ακόλουθα ορίσματα: το σήμα, συχνότητα δειγματοληψίας, μήκος και βήμα παραθύρου, το παράθυρο (σε δευτερόλεπτα) που θα χρησιμοποιηθεί για την ομαλοποίηση της SVM σειράς πιθανοτήτων, ένας αριθμός μεταξύ 0 και 1 που ορίζει πόσο \"αυστηρή\" είναι η κατωφλίωση και τέλος μια boolean μεταβλητή σχετική με τη σχεδίαση του αποτελέσματος. Ας δούμε ένα παράδειγμα:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7uZO7y6Yd2u"
      },
      "source": [
        "from pathlib import Path\n",
        "inputFile = Path(\"trainingData/cat/cat_1.wav\")\n",
        "smoothingWindow = 0.9\n",
        "weight = 0.6\n",
        "!mkdir tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OUeRiFiYJzP"
      },
      "source": [
        "    from pyAudioAnalysis import audioSegmentation as aS\n",
        "    import scipy.io.wavfile as wavfile\n",
        "\n",
        "    [fs, x] = audioBasicIO.read_audio_file(inputFile)\n",
        "    segmentLimits = aS.silence_removal(x, fs, 0.05, 0.05,\n",
        "                                       smoothingWindow, weight, True)\n",
        "    for i, s in enumerate(segmentLimits):\n",
        "        strOut = \"tmp/{0:s}_{1:.3f}-{2:.3f}.wav\".format(inputFile.name[0:-4], s[0], s[1])\n",
        "        wavfile.write(strOut, fs, x[int(fs * s[0]):int(fs * s[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQQLWUZjSH_u"
      },
      "source": [
        "!ls /tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi7od_GsrfM7"
      },
      "source": [
        "Ανάλογα με το είδος της ηχογράφησης, θα πρέπει να χρησιμοποιηθούν διαφορετικές τιμές στο μήκος παραθύρου ομαλοποίησης και στο βάρος πιθανότητας. Πχ (1.0, 0.3) για ήχους που έχουν ανάμεσα μεγάλα διαστήματα σιγής. Για μια ηχογράφηση συνεχής ομιλίας (πχ count2.wav), θα πρέπει να χρησιμοποιηθεί μικρότερο παράθυρο και αυστηρότερο κατώφλι, πχ (0.1, 0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Svh6skxta1p"
      },
      "source": [
        "## Αναγνώριση ομιλητή (Speaker Diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku-_sKMcygxd"
      },
      "source": [
        "Η Αναγνώριση Ομιλητή αυτόματα απαντά στην ερώτηση \"ποιός μίλησε πότε\".\n",
        "Γενικά τα βήματα που ακολουθεί εδώ ο αλγόριθμος είναι:\n",
        "\n",
        "\n",
        "*   Εξαγωγή Χαρακτηριστικών (μικρής και μέσης διάρκειας). Για κάθε μέσης διάρκειας κομμάτι υπολογίζονται στατιστικές, καθώς και τη πιθανότητα να πρόκειται για ανδρική ή γυναικεία φωνή. (Εδώ χρησιμοποιείται και ένα εκπαιδευμένο μοντέλο, το `knnSpeakerFemaleMale`)\n",
        "*   (προαιρετικά) Βήμα FLsD: προβολές των χαρακτηριστικών μέσης διάρκειας με τη προσέγγιση FLsD.\n",
        "*   Ομαδοποίηση: Χρήση μεθόδου k-means (είτε στον αρχικό χώρο των χαρακτηριστικών είτε στον υποχώρο του FLsD). Αν το πλήθος των ομιλητών δεν είναι γνωστό από την αρχή, τότε επαναλαμβάνεται η διαδικασία για μια σειρά αριθμών, και με το κριτήριο Silhouette εκτιμάται το πλήθος των ομιλητών.\n",
        "*   Ομαλοποίηση: Σε αυτό το βήμα συνδιάζονται α) ένα median φίλτρο στις εξαχθείσες ομάδες και b) ομαλοποίηση με Viterbi.\n",
        "\n",
        "Η συνάρτηση `speakerDiarization()` από το αρχείο `audioSegmentation.py` εξάγει μια σειρά από ηχητικά κομμάτια με τις αντίστοιχες εττικέτες τους. (Για λεπτομέρειες στα ορίσματα κοιτάξτε τον κώδικα). Επιπλέον, η συνάρτηση `evaluateSpeakerDiarization()` χρησιμοποιείται από την  `speakerDiarization()` για να συγκρίνει τα αποτελέσματα με την αλήθεια (ground-truth) και να εξάγει μετρικές για την ακρίβεια. .Συγκεκριμένα, υπολογίζονται οι μετρικές cluster purity και  speaker purity. Για να είναι δυνατή η παραγωγή αυτών των μετρικών, χρειάζεται η ύπαρξη του αρχείου αληθείας `.segment` με το ίδιο όνομα με το WAV αρχείο."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9AQNjxmv7L1"
      },
      "source": [
        "ls -la pyAudioAnalysis/pyAudioAnalysis/data/diarizationExample.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogco7m_luW-g"
      },
      "source": [
        "inputFile = \"pyAudioAnalysis/pyAudioAnalysis/data/diarizationExample.wav\"\n",
        "numSpeakers = 4\n",
        "aS.speaker_diarization(inputFile, numSpeakers, lda_dim=0, plot_res=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKpSry8hxxe4"
      },
      "source": [
        "Η συνάρτηση παίρνει ως ορίσματα: -i <fileName>, --num <numberOfSpeakers (0 for unknown)>, --flsd (flag to enable FLsD method). Στο γράφημα που βλέπουμε παραπάνω, με κόκκινο είναι το ground-truth. Στο τίτλο του γραφήματος αναγράφονται και η ακρίβεια του αλγόριθμου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMobsWL7bsC-"
      },
      "source": [
        "## Απεικόνιση ομοιότητας ήχων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaD-lahubvPw"
      },
      "source": [
        "Η επόμενη λειτουργία εξάγει τα χαρακτηριστικά μεγάλης διάρκειας από αρχεία ήχων, εφαρμόζει τεχνική μείωσης διαστάσεων (dimensionality reduction) με PCA ή LDA (που είναι μια εποπτευόμενη [supervised] μέθοδος). Οι κλάσεις -στη δεύτερη περίπτωση= λαμβάνονται από το όνομα των αρχείων. Κοιτάξτε τα ονόματα στον κατάλογο sampleData:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTVGcXrcEOe"
      },
      "source": [
        "!ls sampleData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIB30LwGcNVi"
      },
      "source": [
        "Από τις μειωμένες διαστάσεις που προκύπτουν από την PCA/LDA, υπολογίζεται ένας πίνακας ομοιότητας και με κατωφλίωση προκύπτει ο γράφος ομοιότητας, που αναπαρίσταται σε ένα  διάγραμμα χορδών (chordial). \n",
        "Εδώ βλέπουμε το γράφο ομοιότητας σε δύο άξονες:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0PMiKAJc9Bb"
      },
      "source": [
        "from pyAudioAnalysis import audioVisualization as aV\n",
        "aV.visualizeFeaturesFolder(\"sampleData/\", \"pca\", \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxr7UNZr46nK"
      },
      "source": [
        "Κοιτάξτε το περιεχόμενο των καταλόγων visualization_* που δημιουργήθηκαν:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmjCAmk228CP"
      },
      "source": [
        "# !rm -rf visualization*\n",
        "!ls -la "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbTLfm263-xr"
      },
      "source": [
        "# import IPython\n",
        "# IPython.display.HTML(filename='visualization_Chordial/similarities.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWrISsUG7iIR"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"/tmp/chor\", 'zip', \"visualizationInitial_Chordial\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyAobR806pja"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/tmp/chor.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwZj2GJ4dzNx"
      },
      "source": [
        "## Coding Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlPWKfRdd1QX"
      },
      "source": [
        "Η ακρίβεια του ταξινομητή που φτιάξαμε προηγουμένως δεν είναι ιδιαίτερα καλή, στο περιορισμένο εύρος εκπαίδευσης που είχαμε διαθέσιμο. Μπορείτε να φτιάξετε ένα πρόγραμμα σε python, που να εκμεταλλεύεται την Αφαίρεση Σιγής και να παράγει ένα μοντέλο με καλύτερες αποδόσεις;"
      ]
    }
  ]
}