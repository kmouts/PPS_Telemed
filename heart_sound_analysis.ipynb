{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart_sound_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5XiFB4PDQRKqnDxBCrngA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmouts/PPS_Telemed/blob/main/heart_sound_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA8u39O-wWfq"
      },
      "source": [
        "# Ανάλυση Ήχων Καρδιάς\n",
        "\n",
        "Στο εργαστήριο αυτό θα ασχοληθούμε την Ανάλυση Ήχου, χρησιμοποιώντας μια νέα βιβλιοθήκη Python: **pyAudioAnalysis** [https://github.com/tyiannak/pyAudioAnalysis]. θα χρησιμοποιηθούν δεδομένα από μια Πρόκληση του 2011, ένα Δίκτυο Αριστείας υποστηριζόμενο από την Ευρωπαϊκή Ένωση (http://www.peterjbentley.com/heartchallenge/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVlZHjuZuYav"
      },
      "source": [
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get( 'https://github.com/kmouts/PPS_Telemed/blob/main/heart.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okhTqNZHu1Dk"
      },
      "source": [
        "ls trainingData/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ4G-2R2vH21"
      },
      "source": [
        "Ας εγκαταστήσουμε τις βιβλιοθήκες του προγράμματος."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDsaGSv-x0A3"
      },
      "source": [
        "!git clone https://github.com/tyiannak/pyAudioAnalysis.git\n",
        "!pip install -q -r pyAudioAnalysis/requirements.txt\n",
        "!pip install -q -e pyAudioAnalysis/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehkRphoezcKt"
      },
      "source": [
        "## Εξαγωγή χαρακτηριστικών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_JwQTrwDwp9"
      },
      "source": [
        "Υπάρχουν δύο στάδια στην μεθοδολογία εξαγωγής ηχητικών χαρακτηριστικών:\n",
        "\n",
        "\n",
        "*   Εξαγωγή χαρακτηριστικών Μικρής Διάρκειας (Short-term): Γίνεται με τη χρήση της συνάρτησης `feature_extraction()` από το αρχείο `ShortTermFeatures.py`. Χωρίζει το εισαγόμενο σήμα σε μικρά χρονικά παράθυρα (frames) και υπολογίζει κάποια χαρακτηριστικά για το κάθε παράθυρο. Αυτή η διαδικασία οδηγεί σε μια σειρά από λίστες χαρακτηριστικών για όλο το σήμα\n",
        "*   Εξαγωγή χαρακτηριστικών Μέσης Διάρκειας (Mid-term): Σε πολλές περιπτώσεις το σήμα αντιπροσωπεύεται από στατιστικές των χαρακτηριστικών μικρής διάρκειας. Η συνάρτηση `mid_feature_extraction()` από το αρχείο `MidTermFeatures.py` εξάγει στατιστικές (πχ μέση τιμή και τυπική απόκλιση) σε κάθε σειρά χαρακτηριστικών μικρής διάρκειας.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgQIg11pzqbi"
      },
      "source": [
        "Το pyAudioAnalysis υποστηρίζει την εξαγωγή 34 χαρακτηριστικών (features) από αρχεία ήχου. Ας δούμε 2 από αυτά: **Zero Crossing Rate - ZCR** (The rate of sign-changes of the signal during the duration of a particular frame) και **Energy** (The sum of squares of the signal values, normalized by the respective frame length)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltPu4m212sa3"
      },
      "source": [
        "!apt-get install -qq ffmpeg\n",
        "!apt-get install -qq python3-magic\n",
        "!pip install -q python-magic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN6K8WDyHrk4"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/pyAudioAnalysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGA6JEv6v231"
      },
      "source": [
        "ls -la /content/pyAudioAnalysis/pyAudioAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2tFXvM4-kY"
      },
      "source": [
        "from pyAudioAnalysis import audioBasicIO\n",
        "from pyAudioAnalysis import ShortTermFeatures\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwL7_rGfOYKU"
      },
      "source": [
        "\n",
        "Για να διαβαστούν τα ηχητικά δείγματα καλούμε τη συνάρτηση `read_audio_file()` από το αρχείο `audioBasicIO.py`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6LKS9BWOgH4"
      },
      "source": [
        "[Fs, x] = audioBasicIO.read_audio_file(\"trainingData//normal/normal_201101070538.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBD0kabrORhY"
      },
      "source": [
        "# Διάγραμμα με την κυματομορφή\n",
        "import numpy\n",
        "timeX = numpy.arange(0, x.shape[0] / float(Fs), 1.0 / Fs)\n",
        "plt.plot(timeX, x)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oki8WE7j89ad"
      },
      "source": [
        "Ο  επόμενος κώδικας χρησιμοποιεί τη συνάρτηση `feature_extraction()` από το αρχείο `ShortTermFeatures.py` για την εξαγωγή χαρακτηριστικών μικρής διάρκειας ενός ηχητικού σήματος. Θέτουμε χρονικό παράθυρο (frame) 50 msecs και βήμα 25 msecs (με 50% επικάλυψη)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN2NHOZd5mtb"
      },
      "source": [
        "F, f_names = ShortTermFeatures.feature_extraction(x, Fs, 0.050*Fs, 0.025*Fs)\n",
        "plt.subplot(2,1,1); plt.plot(F[0,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[0]) \n",
        "plt.subplot(2,1,2); plt.plot(F[1,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[1]); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69rgT0Lv79IY"
      },
      "source": [
        "O παραπάνω κώδικας επίσης κάνει το διάγραμμα σειράς των δύο πρώτων χαρακτηριστικών: `zero crossing rate` και `signal energy`. Η συνάρτηση `feature_extraction()` επιστρέφει έναν πίνακα numpy  με 34 γραμμές και  N στήλες, όπου N το πλήθος των short-term frames που χωράνε στην εγγραφή του ήχου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3cag-_LHKNP"
      },
      "source": [
        "## Οπτική Ανάλυση του Ήχου"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rup_OWznIVHh"
      },
      "source": [
        "### Φασματικό Διάγραμμα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWoK3Ga8LPQJ"
      },
      "source": [
        "[fs, x] = audioBasicIO.read_audio_file(\"trainingData/normal/normal_201101070538.wav\")\n",
        "x = audioBasicIO.stereo_to_mono(x)\n",
        "specgram, TimeAxis, FreqAxis = ShortTermFeatures.spectrogram(x, fs, round(fs * 0.040),round(fs * 0.040), True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOEJsbLLMq2T"
      },
      "source": [
        "### Χρωματικό Διάγραμμα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqcAJk0yMuLe"
      },
      "source": [
        "specgram, TimeAxis, FreqAxis = ShortTermFeatures.chromagram(x, fs, round(fs * 0.040),\n",
        "                                                 round(fs * 0.040), True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr77Zz6RMjKr"
      },
      "source": [
        "## Εκπαίδευση ενός Ταξινομητή Ήχου\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugspvSM5QCM3"
      },
      "source": [
        "Στην συνέχεια θα εκπαιδεύσουμε έναν ταξινομητή που χρησιμοποιεί Cross-Validation για να διαλέξει την βέλτιστη παράμετρο για τον ταξινομητή (πχ τη παράμετρο soft margin C για SVM, το πλήθος των δέντρων για Random Forests, ο αριθμός των γειτόνων k για Knn κλπ.) Το παραγόμενο μοντέλο σώζεται στη θέση που ορίζουμε με την παράμετρο –o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_D6UXRgYHog"
      },
      "source": [
        "Πρώτα όμως ας φορτώσουμε τα αρχεία εκπαίδευσης, και τα αρχεία για το τελικό τέστ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_4QqI4dOPD4"
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUlGs507NbcN"
      },
      "source": [
        "!python pyAudioAnalysis/pyAudioAnalysis/audioAnalysis.py trainClassifier -i trainingData/artifact/ trainingData/extrah/ trainingData/murmur/ trainingData/normal/ --method svm -o models/svmSM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpNFWbz50i8s"
      },
      "source": [
        "%ls -la models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKr2OQEUPeVh"
      },
      "source": [
        "### Ταξινόμηση ‘άγνωστων’ ήχων\n",
        "\n",
        "Ας δούμε τώρα πόσο καλά τα πάει ο ταξινομητής μας:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnJl80_Ptxk"
      },
      "source": [
        "!python pyAudioAnalysis/pyAudioAnalysis/audioAnalysis.py classifyFolder -i sampleData/ --model svm --classifier models/svmSM --details\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNgAJX7RHTZ"
      },
      "source": [
        "## Αφαίρεση σιγής"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN8XT4yvoBZi"
      },
      "source": [
        "Η συνάρτηση `silence_removal()` από το αρχείο `audioSegmentation.py` παίρνει σαν είσοδο ένα αρχείο ηχογράφησης και εξάγει τμήματα που αντιστοιχούν σε ηχητικά γεγονότα. Με αυτό το τρόπο, τμήματα \"σιγής\" αφαιρούνται από το σήμα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kHUyXC-RLmj"
      },
      "source": [
        "Αυτό επιτυγχάνεται με μια ημι-εποπτευόμενη (semi-supervised) προσέγγιση: Πρώτα εκπαιδεύεται ένα SVM μοντέλο στο να διακρίνει frames υψηλής/χαμηλής ενέργειας. Για το σκοπό αυτό γίνεται χρήση των 10% των υψηλότερων και 10% των χαμηλότερων ενεργειακά πλαισίων. Το παραγόμενο μοντέλο τρέχει σε όλο το αρχείο (με έξοδο την πιθανότητα) και με δυναμική κατωφλίωση (επιλογή –weight) για  να διακρίνει τα ενεργά τμήματα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF_go4xMpzIu"
      },
      "source": [
        "Η συνάρτηση `silence_removal()` έχει τα ακόλουθα ορίσματα: το σήμα, συχνότητα δειγματοληψίας, μήκος και βήμα παραθύρου, το παράθυρο (σε δευτερόλεπτα) που θα χρησιμοποιηθεί για την ομαλοποίηση της SVM σειράς πιθανοτήτων, ένας αριθμός μεταξύ 0 και 1 που ορίζει πόσο \"αυστηρή\" είναι η κατωφλίωση και τέλος μια boolean μεταβλητή σχετική με τη σχεδίαση του αποτελέσματος. Ας δούμε ένα παράδειγμα:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7uZO7y6Yd2u"
      },
      "source": [
        "from pathlib import Path\n",
        "inputFile = Path(\"trainingData/normal/normal_201101070538.wav\")\n",
        "smoothingWindow = 0.9\n",
        "weight = 0.6\n",
        "!mkdir tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OUeRiFiYJzP"
      },
      "source": [
        "    from pyAudioAnalysis import audioSegmentation as aS\n",
        "    import scipy.io.wavfile as wavfile\n",
        "\n",
        "    [fs, x] = audioBasicIO.read_audio_file(inputFile)\n",
        "    segmentLimits = aS.silence_removal(x, fs, 0.05, 0.05,\n",
        "                                       smoothingWindow, weight, True)\n",
        "    for i, s in enumerate(segmentLimits):\n",
        "        strOut = \"tmp/{0:s}_{1:.3f}-{2:.3f}.wav\".format(inputFile.name[0:-4], s[0], s[1])\n",
        "        wavfile.write(strOut, fs, x[int(fs * s[0]):int(fs * s[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQQLWUZjSH_u"
      },
      "source": [
        "!ls /tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi7od_GsrfM7"
      },
      "source": [
        "Ανάλογα με το είδος της ηχογράφησης, θα πρέπει να χρησιμοποιηθούν διαφορετικές τιμές στο μήκος παραθύρου ομαλοποίησης και στο βάρος πιθανότητας. Πχ (1.0, 0.3) για ήχους που έχουν ανάμεσα μεγάλα διαστήματα σιγής. Για μια ηχογράφηση συνεχής ομιλίας (πχ count2.wav), θα πρέπει να χρησιμοποιηθεί μικρότερο παράθυρο και αυστηρότερο κατώφλι, πχ (0.1, 0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMobsWL7bsC-"
      },
      "source": [
        "## Απεικόνιση ομοιότητας ήχων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaD-lahubvPw"
      },
      "source": [
        "Η επόμενη λειτουργία εξάγει τα χαρακτηριστικά μεγάλης διάρκειας από αρχεία ήχων, εφαρμόζει τεχνική μείωσης διαστάσεων (dimensionality reduction) με PCA ή LDA (που είναι μια εποπτευόμενη [supervised] μέθοδος). Οι κλάσεις -στη δεύτερη περίπτωση= λαμβάνονται από το όνομα των αρχείων. Κοιτάξτε τα ονόματα στον κατάλογο sampleData:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTVGcXrcEOe"
      },
      "source": [
        "!ls sampleData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIB30LwGcNVi"
      },
      "source": [
        "Από τις μειωμένες διαστάσεις που προκύπτουν από την PCA/LDA, υπολογίζεται ένας πίνακας ομοιότητας και με κατωφλίωση προκύπτει ο γράφος ομοιότητας, που αναπαρίσταται σε ένα  διάγραμμα χορδών (chordial). \n",
        "Εδώ βλέπουμε το γράφο ομοιότητας σε δύο άξονες:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0PMiKAJc9Bb"
      },
      "source": [
        "from pyAudioAnalysis import audioVisualization as aV\n",
        "aV.visualizeFeaturesFolder(\"sampleData/\", \"pca\", \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxr7UNZr46nK"
      },
      "source": [
        "Κοιτάξτε το περιεχόμενο των καταλόγων visualization_* που δημιουργήθηκαν:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmjCAmk228CP"
      },
      "source": [
        "# !rm -rf visualization*\n",
        "!ls -la "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbTLfm263-xr"
      },
      "source": [
        "# import IPython\n",
        "# IPython.display.HTML(filename='visualization_Chordial/similarities.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWrISsUG7iIR"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"/tmp/chor\", 'zip', \"visualizationInitial_Chordial\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyAobR806pja"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/tmp/chor.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwZj2GJ4dzNx"
      },
      "source": [
        "## Coding Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlPWKfRdd1QX"
      },
      "source": [
        "*\tH βιβλιοθήκη pyAudioAnalysis έχει την δυνατότητα εξαγωγής του \n",
        "ρυθμού σε ένα κομμάτι ήχου, με τη μορφή του BPM (Beats per Minute). Πχ δοκιμάστε με command line την εντολή:\n",
        "`python audioAnalysis.py beatExtraction -i  C:/LAB/trainingData/normal/normal_201101070538.wav  --plot`\n",
        "*\tΦτιάξτε ένα πρόγραμμα σε python που να εξάγει τα BPMs σε όλα τα αρχεία στον κατάλογο sampleData, ώστε να μπορούμε να τα συγκρίνουμε μεταξύ τους.\n"
      ]
    }
  ]
}